id: 1.1
epic: 1
title: Upload & Job Orchestration
status: draft
story: |
  As a user, I want to upload a contract file (PDF/DOCX) so that the system can process it and provide analysis.
acceptance_criteria:
  - POST /contracts accepts PDF/DOCX ≤10MB; returns job_id
  - GET /jobs/{id} returns status: queued|running|done|error (+ error reason)
  - On done, analysis record exists with filename, size, created_at
  - Latency budget: enqueue < 500ms server time
notes:
  - Virus/size checks server‑side; signed upload URL optional
tasks: []
dev_agent_record:
  proposed_tasks:
    - backend: Implement POST /api/contracts and GET /api/jobs/{id}
    - service: Add services/tasks.py with enqueue() via BackgroundTasks
    - storage: Persist source + metadata under .data/analyses/{analysis_id}
    - frontend: /new FileDrop, call upload, poll job, route on done
    - tests: API unit + integration for upload, polling, error paths
  decisions_needed:
    - Confirm BackgroundTasks for MVP; Celery in phase-2
    - Enforce 10MB limit server-side; clarify client pre-check

  dev_spec:
    - api: POST /api/contracts (pdf/docx ≤10MB) → {job_id, analysis_id, status: queued}
    - api: GET /api/jobs/{id} → {id,status,analysis_id?,error_reason?}
    - services: storage.save_upload (size capped), tasks.new_job/process_job (write analysis.json)
    - persistence: .data/analyses/{id}/{source_filename}, analysis.json
    - config: JOB_SYNC=1 for sync processing in tests/dev

  qa_tests:
    - unit: unsupported type → 415; >10MB → 413; missing file → 422
    - integ: upload → 201 then job status → done; analysis.json exists
    - perf: enqueue returns <500ms (best-effort assertion)
