id: 2.4
epic: 2
title: Token Ledger & Caps
status: Ready for Review
story: |
  As a system administrator, I need to track token usage for LLM interactions and enforce caps to control costs and prevent abuse.
acceptance_criteria:
  - Track tokens_per_doc; expose metric
  - Hard cap triggers needs_review; logged with reason
  - LLM provider off by default
notes:
  - Only applies if LLM features are enabled via settings (Story 5.1).
  - Ledger should be a simple data structure to track usage per analysis.
  - Integration point with the LLM gate (part of Story 2.2 or a related task).
  - Needs to be performant and thread-safe if concurrent processing occurs.
tasks: []
dev_agent_record:
  proposed_tasks:
    - backend: Implement token ledger per analysis + cap enforcement (needs_review)
    - backend: Expose tokens_per_doc metric to admin metrics aggregator
    - integration: Hook into detector runner (LLM off by default; gate path stubbed)
    - tests: Cap triggers; off-by-one edges; provider off path
  dependencies:
    - story: 5.1-org-settings
  open_decisions:
    - Behavior when cap exceeded: 1) Mark only; 2) Short-circuit LLM paths [Selected: 2]
    - Cap value and override mechanism: 1) Global env TOKEN_CAP_PER_DOC [Current]; 2) Org-level settings in 5.1 [Recommended]; 3) Per-analysis override [Deferred]

  agent_model_used: dev
  debug_log:
    - cmd: .\\.venv\\Scripts\\python.exe -m pytest apps/api/blackletter_api/tests -q
      result: tests executed locally without failures; token ledger and metrics tests passed
  completion_notes:
    - Added thread-safe per-analysis token ledger persisted at `.data/analyses/{id}/tokens.json`.
    - Enforced hard cap via `TOKEN_CAP_PER_DOC` (default 20000); marks `needs_review` with reason and short-circuits LLM paths.
    - Provider OFF by default; persisting zeroed ledger for visibility when disabled.
    - Exposed admin metrics at `GET /api/admin/metrics` including `tokens_per_doc` entries.
    - QA validation: Off-by-one and provider-off unit tests pass; integration `test_token_caps_enforced_and_metrics_exposed` passes; behavior matches dev_spec.
  file_list:
    - apps/api/blackletter_api/services/token_ledger.py (new)
    - apps/api/blackletter_api/routers/admin.py (new)
    - apps/api/blackletter_api/main.py (updated: register admin router)
    - apps/api/blackletter_api/services/detector_runner.py (updated: ledger integration)
    - apps/api/blackletter_api/tests/unit/test_token_ledger.py (new)
    - apps/api/blackletter_api/tests/integration/test_caps_metrics.py (updated: implements test)
  change_log:
    - 2025-08-29: Implemented token ledger, cap enforcement, admin metrics; added tests

### dev_spec

- Ledger: `services/token_ledger.py` thread-safe counters per analysis (per-analysis `threading.Lock`); persist at `.data/analyses/{id}/tokens.json`.
- Enforcement: env `TOKEN_CAP_PER_DOC` (default 20000); on exceed or equal, mark `needs_review` with reason and short-circuit LLM-dependent paths while continuing non-LLM detectors.
- Provider disabled: `LLM_PROVIDER_ENABLED=0` persists a zeroed ledger for visibility.
- Metrics: exposed via `GET /api/admin/metrics` as `{ tokens_per_doc: [ { analysis_id, total_tokens, cap, needs_review } ], total_analyses }`.
- Discovery: Admin metrics derive from `list_all_ledgers()` scanning `.data/analyses/*/tokens.json`.

### qa_tests

- Accumulate tokens precisely; concurrent add safe (multi-thread increments land correctly once; no races).
- Cap triggers needs_review at threshold; off-by-one edges (equals cap flips to True once).
- Negative/zero token additions are ignored (no mutation).
- Corrupted `tokens.json` recovers to defaults without pipeline failure.
- Provider-off path persists zeroed ledger; persistence verified on disk.
- Metrics endpoint returns expected shape and types; includes the capped analysis with `needs_review=true`.
- Reason includes `token_cap_exceeded` substring when cap breached.
- End-to-end: running `run_detectors` on a large extraction accrues tokens, hits cap, and metrics reflect the state.
