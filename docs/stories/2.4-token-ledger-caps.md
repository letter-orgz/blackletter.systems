id: 2.4
epic: 2
title: Token Ledger & Caps
status: draft
story: |
  As a system administrator, I need to track token usage for LLM interactions and enforce caps to control costs and prevent abuse.
acceptance_criteria:
  - Track tokens_per_doc; expose metric
  - Hard cap triggers needs_review; logged with reason
  - LLM provider off by default
notes:
  - Only applies if LLM features are enabled via settings (Story 5.1).
  - Ledger should be a simple data structure to track usage per analysis.
  - Integration point with the LLM gate (part of Story 2.2 or a related task).
  - Needs to be performant and thread-safe if concurrent processing occurs.
tasks: []
dev_agent_record:
  proposed_tasks:
    - backend: Implement token ledger per analysis + cap enforcement (needs_review)
    - backend: Expose tokens_per_doc metric to admin metrics aggregator
    - integration: Hook into detector runner (LLM off by default; gate path stubbed)
    - tests: Cap triggers; off-by-one edges; provider off path
  dependencies:
    - story: 5.1-org-settings
  open_decisions:
    - Cap value and override mechanism; behavior when exceeded (short-circuit vs. mark only)

### dev_spec

- Ledger: `services/token_ledger.py` thread-safe counters per analysis; persist `.data/analyses/{id}/tokens.json`.
- Enforcement: env `TOKEN_CAP_PER_DOC` (default 20000); when exceeded, mark needs_review with reason and short-circuit LLM paths.
- Metrics: exposed via `GET /api/admin/metrics` (see 4.1).

### qa_tests

- Accumulate tokens precisely; concurrent add safe.
- Cap triggers needs_review at threshold; off-by-one edges.
- Provider-off path returns zeros; persistence verified.
