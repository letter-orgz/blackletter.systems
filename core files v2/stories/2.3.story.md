# Story 2.3: Weak-Language Lexicon v0

**Status**: Draft

**Story**:
As a detection system, I need to apply a lexicon of weak language terms to findings to potentially downgrade a 'Pass' verdict to 'Weak' if no strong counter-anchors are found.

**Acceptance Criteria**:
- Apply lexicon inside evidence window
- Downgrade Passâ†’Weak unless counter-anchor present
- Configurable lexicon file

**Dev Notes**:

**Previous Story Insights**:
- The detector runner (`2.2-detector-runner.md`) is now in place and produces initial verdicts. This story will add a post-processing step to that.

**Data Models**:
- The `Finding` Pydantic model will be used. No changes to the schema are expected. [Source: architecture/5-data-model-pydantic.md]
```python
class Finding(BaseModel):
    detector_id: str
    rule_id: str
    verdict: Literal["pass","weak","missing","needs_review"]
    snippet: str
    page: int
    start: int
    end: int
    rationale: str
    reviewed: bool = False
```

**API Specifications**:
- No new endpoints are required for this story. This is a backend processing enhancement. [Source: architecture/6-api-contracts-mvp-frozen.md]

**Component Specifications**:
- No specific guidance found in architecture docs.

**File Locations**:
- New logic should be implemented in `apps/api/blackletter_api/services/weak_lexicon.py`.
- The lexicon file should be located at `apps/api/blackletter_api/rules/lexicons/weak_language.yaml`.
- The `detector_runner.py` service will be modified to incorporate this new logic.
[Source: architecture/source_tree.md]

**Testing Requirements**:
- Unit tests should cover:
    - Lexicon matches causing a downgrade.
    - Counter-anchor presence preventing a downgrade.
    - Case-insensitive and whole-word boundary matching.
    - The feature toggle disabling the functionality.
[Source: architecture/10-quality-gates-testing.md]

**Technical Constraints**:
- The implementation must adhere to the existing tech stack (Python 3.11, FastAPI, Pydantic). [Source: architecture/tech_stack.md]
- Code should be formatted with `black` and linted with `ruff`. [Source: architecture/coding_standards.md]

**Tasks / Subtasks**:

1.  **Backend: Implement Lexicon Loading (AC: 3)**
    - In `rulepack_loader.py`, add logic to load `rules/lexicons/weak_language.yaml`.
    - The lexicon should be made available to the `detector_runner` service.
    - [Source: architecture/4-service-decomposition.md]
2.  **Backend: Implement Downgrade Logic (AC: 1, 2)**
    - Create a new service `weak_lexicon.py`.
    - Implement a function `apply_downgrade(findings, windows, counter_anchors)` that post-processes findings.
    - This function should downgrade 'Pass' to 'Weak' based on the lexicon and counter-anchors.
    - Integrate this function into `detector_runner.py`.
    - [Source: architecture/4-service-decomposition.md]
3.  **Config: Add Feature Toggle**
    - Add a feature toggle `WEAK_LEXICON_ENABLED` to `core-config.yaml`.
    - The downgrade logic should only run if this is enabled.
4.  **Tests: Unit Tests (AC: 1, 2, 3)**
    - In `tests/unit/`, add `test_weak_lexicon.py`.
    - Add tests for the downgrade logic, counter-anchor overrides, and word boundaries.
    - Add a test to ensure the feature toggle is respected.
    - [Source: architecture/10-quality-gates-testing.md]
